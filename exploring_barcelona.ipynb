{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a> \n",
    "# Capstone Project - The Battle of the Neighborhoods\n",
    "### Applied Data Science Capstone by IBM/Coursera\n",
    "\n",
    "# Table Of Contents\n",
    "* [Introduction: Business Problem](#intro)\n",
    "* [Initial Setup](#setup)\n",
    "* [Data Sources](#data)\n",
    "    * [List of Barcelona Neighbourhoods](#data1)\n",
    "    * [list of avg house prices](#data2)\n",
    "    * [geoJSON definitions of all the neighbourhood data](#data3)\n",
    "    * [merging location data](#data4)\n",
    "    * [venue data from FourSquare](#data5)\n",
    "    * [venue category taxonomy from FourSquare](#data6)\n",
    "* [Data Processing](#processing)\n",
    "* [Investigations](#investigations)\n",
    "    * [price by district](#inv1)\n",
    "    * [price effect each type of venue](#inv2)\n",
    "    * [identifying types of districts](#inv3)\n",
    "    * [underpriced/overpriced neighbourhoods by venue](#inv4)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Business Problem <a id=\"intro\"></a> \n",
    "\n",
    "Conventions\n",
    "Barcelona is (at the time of writing) made up of 10 districts (\"districtes\"), 73 neighbourhoods (\"barris\") and 1069 sub-neighbourhoods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Initial setup <a id=\"setup\"></a>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install additional libraries that we might not already have\n",
    "Geopandas is really powerful and allows us to do a lot of the calculations that we'd need to do manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I started using PIP but found I got a bunch of incompatibility issues so switched to using Conda\n",
    "# i needed this in order to prevent conda compatibility issues\n",
    "#!conda config --set channel_priority strict\n",
    "#!conda install --channel conda-forge shapely folium pandas numpy geopandas  matplotlib geopy scikit-learn python-dotenv  -y\n",
    "#!conda install --channel conda-forge openpyxl -y\n",
    "#!conda install --channel conda-forge nodejs -y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm using these variables to control whether I'm downloading or repulling the data from the API or loading from local files already pulled\n",
    "\n",
    "download_all_data = False\n",
    "load_venues_from_file = True\n",
    "load_venue_data_from_api = False\n",
    "write_venues_to_file = False\n",
    "\n",
    "\n",
    "venue_data_from_foursquare = True #1.5.1\n",
    "price_by_district = True #\n",
    "price_effect_each_type_of_venue = True\n",
    "identifying_types_of_districts = True\n",
    "underpriced_overpriced_neighbourhoods_by_venue = True\n",
    "\n",
    "#Uncomment the below if this is the first time you're running\n",
    "#download_all_data = True\n",
    "#load_venues_from_file = False\n",
    "#load_venue_data_from_api = True\n",
    "#write_venues_to_file = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import math\n",
    "from IPython.display import JSON\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import json # library to handle JSON files\n",
    "\n",
    "\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "#from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "import folium # map rendering library\n",
    "\n",
    "from shapely.geometry import Polygon, mapping, Point\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pickle \n",
    "\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets setup our coordinates for Barcelona which we'll use for a lot of our mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Barcelona, ES'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"bcn_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Barcelona are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br>\n",
    "## 1 Data sources <a id=\"data\"></a>\n",
    "---\n",
    "\n",
    "\n",
    "We have 4 different datasources that we're going to need to be able to perform the analyses we're wanting\n",
    "1. List of all the Barcelona neighbourhoods\n",
    "2. List of average house prices\n",
    "3. GeoJSON representations of all of the neighbourhoods\n",
    "4. The venue details from FourSquare\n",
    "5. The FourSquare categorization taxonomy\n",
    "<br><br>\n",
    "\n",
    "### 1.1 list of Barcelona neighbourhoods <a id=\"data1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the names of the different districts and neighbourhoods in BCN, It's available from the Barcelona Ajuntament (Council)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to actually download the file - commented for when you've alreay downloaded the file\n",
    "if(download_all_data):\n",
    "    print(\"Downloading\")\n",
    "    !wget -q -O 'barcelona_neighbourhoods.csv' https://opendata-ajuntament.barcelona.cat/data/dataset/8f144d2c-1185-4e5c-9b97-ac930eeffca8/resource/d7aa700f-c2dc-4ffb-b5c2-62f494dd3c34/download/2017_superficie.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our file in and rename some of the columns to allow linking later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios_df = pd.read_csv('barcelona_neighbourhoods.csv')\n",
    "barrios_df.rename(columns={\"Codi_Barri\": \"BARRI\"}, inplace=True)\n",
    "barrios_df.dropna()\n",
    "#barrios_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 1.2 list of avg house prices <a id=\"data2\"></a>\n",
    "This file has each of the districs and the avg property price per m2 in 2015 - again this is available from the city council."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to actually download the file - commented for when you've alreay downloaded the file\n",
    "if(download_all_data):\n",
    "    print(\"Downloading\")\n",
    "    !wget -q -O 'barcelona_prices.csv' https://opendata-ajuntament.barcelona.cat/data/dataset/59975890-c615-4080-8dd7-ef1406085590/resource/cd9118c6-427c-4390-8334-3670cc3f3f6a/download/2015_habitatges_2na_ma2015.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.read_csv('barcelona_prices.csv',encoding = 'latin_1')\n",
    "prices_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to link to our other data, we need to extract the neighbourhood id from the neighbourhood column and we can remove some unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zf(value):\n",
    "    return str(value).zfill(2)\n",
    "def rc(value):\n",
    "    return pd.to_numeric(value.replace('.',''))\n",
    "\n",
    "\n",
    "#prices_df.rename(columns={\"Codi_Barri\": \"BARRI\"}, inplace=True)\n",
    "prices_df = prices_df.join( prices_df[\"Barris\"].str.split(\".\", n = 1, expand = True) )\n",
    "prices_df.rename(columns={'Dte.': \"Codi_Districte\",'2015':'price_per_m2', 0:'BARRI_lu',1:'Nom_Barri_lu'}, inplace=True)\n",
    "prices_df.dropna(inplace = True)\n",
    "prices_df = prices_df[prices_df['price_per_m2'] != 'n.d.']\n",
    "#prices_df.astype({'BARRI': 'str'}).dtypes\n",
    "#prices_df['BARRI'] = prices_df['BARRI'].apply(zf);\n",
    "prices_df['price_per_m2'] = prices_df['price_per_m2'].apply(rc)\n",
    "prices_df = prices_df.astype({'BARRI_lu': 'int64','price_per_m2':'int64'})\n",
    "prices_df.sort_values(by=['price_per_m2'], inplace=True)\n",
    "prices_df.drop(['Codi_Districte', 'Barris'], axis=1, inplace = True)\n",
    "prices_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 1.3 the geoJSON definitions of all the neighbourhood data <a id=\"data3\"></a>\n",
    "This file gives the sub neighbourhoods coded into geojson, and will allow us to map our data very acurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to actually download the file - commented for when you've alreay downloaded the file\n",
    "if(download_all_data):\n",
    "    print(\"Downloading\")\n",
    "    !wget -q -O 'barcelona_seccio-censal.geojson'  https://raw.githubusercontent.com/martgnz/bcn-geodata/master/seccio-censal/seccio-censal.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the file in, and convert datatypes that we're going to be linking later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods = gpd.read_file('barcelona_seccio-censal.geojson',crs={'init':'epsg:4326'})\n",
    "df_hoods = df_hoods.astype({'BARRI': 'int64'})\n",
    "\n",
    "#df_hoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 1.4 merging location data <a id=\"data4\"></a>\n",
    "Before we can continuee, we need to merge some of our location data, so that we can look at both neighbourhoods and districts together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hoods = df_hoods.merge(barrios_df.set_index('BARRI'), how='inner', on='BARRI')\n",
    "df_hoods = df_hoods.merge(prices_df, how='inner', left_on='BARRI',right_on='BARRI_lu')\n",
    "df_hoods['neighbourhood'] = df_hoods['Nom_Barri'] + ' - ' + df_hoods.LITERAL\n",
    "df_hoods.drop(['BARRI_lu', 'Nom_Barri_lu'], axis=1, inplace = True)\n",
    "\n",
    "df_hoods.index.name = 'id'\n",
    "df_hoods['id'] = df_hoods.index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 1.5 our venue data from FourSquare <a id=\"data5\"></a>\n",
    "In order to get our venue data from the FourSquare API, we need to pass in a centrepoint and a radius.\n",
    "To do this we'll need to look at each of our sub-neighbourhoods, and calculate these two values.\n",
    "Let's start with the centrepoints.\n",
    "#### 1.5.1 centerpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the built in GeoPandas centroid functionality to calculate the centre point for each sub neighbourhood like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods['centre_lat']=df_hoods['geometry'].centroid.y\n",
    "df_hoods['centre_lng']=df_hoods['geometry'].centroid.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our shapes in blue, and our centroids in red to check that everything looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create map of Barcelona using latitude and longitude values\n",
    "map_bcn = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "if(venue_data_from_foursquare):\n",
    "   \n",
    "    folium.GeoJson(\n",
    "        df_hoods.to_json(),\n",
    "        name='geojson'\n",
    "    ).add_to(map_bcn)\n",
    "\n",
    "\n",
    "    # add markers to map\n",
    "    for lat, lng, borough, neighbourhood in zip(df_hoods['centre_lat'], df_hoods['centre_lng'], df_hoods['Nom_Barri'], df_hoods['LITERAL']):\n",
    "        label = '{}, {}'.format(neighbourhood, borough)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color='red',\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "\n",
    "\n",
    "map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This looks great, however, it's clear that the sizes of the subneighbourhoods are much bigger than others, they're also of different shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 radiuses\n",
    "So how should we choose the right search radius for Foursquare data?\n",
    "\n",
    "Lets take a look at some examples of the issue with 3 subneighbourhoods (032,040 and 039) in the Barceloneta district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_hoods = ['032', '040','039']\n",
    "\n",
    "df_problems = df_hoods[df_hoods.LITERAL.isin(problem_hoods) & df_hoods.Codi_Districte.eq(1) ]\n",
    "\n",
    "\n",
    "df_problems.at[97, 'FHEX_COLOR'] = '#FF0000'\n",
    "df_problems.at[104, 'FHEX_COLOR'] = '#00FF00'\n",
    "df_problems.at[105, 'FHEX_COLOR'] = '#0000FF'\n",
    "df_problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot these three neighbourhoods, along with the 500m radiuses that are standard with FourSquare, we can see that the two smaller areas maked with green and blue (areas 039 and 040) almost totally overlap each other.\n",
    "\n",
    "\n",
    "Not only that, but if we look at the Museum of Catalan History highlighed by the purple circle, it would be included in both the catchment areas of 039 and 040, but this isn't correct, as it's actually situated within area 32 shown in red.\n",
    "\n",
    "With a 500m catchment area (the red circle) , area 032 (shown in red) wouldn't include this venue.\n",
    "\n",
    "So we need to have a custom catchement area for each sub neighbourhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0,\n",
    "        'fillColor': feature['properties']['FHEX_COLOR'] \n",
    "    }\n",
    "\n",
    "if(venue_data_from_foursquare):\n",
    "    # create map of Barcelona using latitude and longitude values\n",
    "    map_bcn = folium.Map(location=[df_problems.iloc[0].centre_lat, df_problems.iloc[0].centre_lng], zoom_start=15)\n",
    "    folium.GeoJson(\n",
    "        df_problems.to_json(),\n",
    "        name='geojson',\n",
    "        style_function=style_function\n",
    "    ).add_to(map_bcn)\n",
    "    # add markers to map\n",
    "    for lat, lng, borough, neighbourhood,colour in zip(df_problems['centre_lat'], df_problems['centre_lng'], df_problems['Nom_Barri'], df_problems['LITERAL'],df_problems['FHEX_COLOR']):\n",
    "        label = '{}, {}'.format(neighbourhood, borough)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color=colour,\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "        folium.Circle([lat, lng],\n",
    "                        radius=500,\n",
    "                      color= colour\n",
    "                       ).add_to(map_bcn)\n",
    "    folium.CircleMarker(\n",
    "            [41.380711, 2.185559],\n",
    "            radius=15,\n",
    "            color='black',\n",
    "            fill=True,\n",
    "            fill_color='purple',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we need to find the size of the radius that should apply to each area.\n",
    "Lets get the enclosing box that would cover the area in question\n",
    "Then we need to calculate the length of the sides of the box in meters - for this I'm using Haversine's formula.  There's probably a way to do this directly in GeoPandas but sometimes doing it yourself isn't a bad thing.\n",
    "Once we have all the lengths of the sides, we get the max, and divide by 2 to find an appropriate radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def haversine(coord1, coord2):\n",
    "\n",
    "    # Coordinates in decimal degrees (e.g. 2.89078, 12.79797)\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "    R = 6371000  # radius of Earth in meters\n",
    "    phi_1 = math.radians(lat1)\n",
    "    phi_2 = math.radians(lat2)\n",
    "\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2.0) ** 2 + math.cos(phi_1) * math.cos(phi_2) * math.sin(delta_lambda / 2.0) ** 2\n",
    "\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    meters = R * c  # output distance in meters\n",
    "    km = meters / 1000.0  # output distance in kilometers\n",
    "\n",
    "    meters = round(meters)\n",
    "    km = round(km, 3)\n",
    "    #print(f\"Distance: {meters} m\")\n",
    "    #print(f\"Distance: {km} km\")\n",
    "    return meters\n",
    "\n",
    "def calc_stats(coords):\n",
    "    #x_max = max(coords[0][0],coords[1][0],coords[2][0],coords[3][0])*100002\n",
    "    #y_max = max(coords[0][1],coords[1][1],coords[2][1],coords[3][1])*100002\n",
    "    tot_max = max(coords)\n",
    "    radius = tot_max/2\n",
    "    return {'tot_max':tot_max,'radius':radius}\n",
    "\n",
    "def calc_dist(coord1, coord2):\n",
    "    dist = haversine(coord1,coord2)\n",
    "    #dist1 = abs(coord1[0] - coord2[0])\n",
    "    #dist2 = abs(coord1[1] - coord2[1])\n",
    "    return dist\n",
    "\n",
    "def get_radius(env):\n",
    "    coors = list(zip(*env.exterior.coords.xy))\n",
    "    length = [calc_dist(coors[0],coors[1])]\n",
    "    length.append(calc_dist(coors[1],coors[2]))\n",
    "    length.append(calc_dist(coors[2],coors[3]))\n",
    "    length.append(calc_dist(coors[3],coors[4]))\n",
    "\n",
    "    stats = calc_stats(length)\n",
    "    radius = stats['radius']\n",
    "    #lets increase sligtly to account for the edges of the bounding box\n",
    "    radius = radius * 1.15 \n",
    "    #print(stats)\n",
    "    return round(radius,0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the envelopes and apply our new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envelopes = df_problems['geometry'].envelope\n",
    "df_problems['radius'] = envelopes.apply(get_radius)\n",
    "df_problems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the bounding boxes, and the new radiuses on our map and see if it's worked.\n",
    "We're looking to see if the Catalan History Museum in now correctly included within the radius of the sub-neighbourhood it's in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0,\n",
    "        'fillColor': feature['properties']['FHEX_COLOR'] \n",
    "    }\n",
    "\n",
    "if(venue_data_from_foursquare):\n",
    "    # create map of Barcelona using latitude and longitude values\n",
    "    map_bcn = folium.Map(location=[df_problems.iloc[0].centre_lat, df_problems.iloc[0].centre_lng], zoom_start=15)\n",
    "    folium.GeoJson(\n",
    "        df_problems.to_json(),\n",
    "        name='geojson',\n",
    "        style_function=style_function\n",
    "    ).add_to(map_bcn)\n",
    "\n",
    "\n",
    "    folium.GeoJson(\n",
    "        envelopes.to_json(),\n",
    "        name='geojson'\n",
    "    ).add_to(map_bcn)\n",
    "\n",
    "    # add markers to map\n",
    "    for lat, lng, borough, neighbourhood,colour,radius in zip(df_problems['centre_lat'], df_problems['centre_lng'], df_problems['Nom_Barri'], df_problems['LITERAL'],df_problems['FHEX_COLOR'],df_problems['radius']):\n",
    "        label = '{}, {}'.format(neighbourhood, borough)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color=colour,\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "        folium.Circle([lat, lng],\n",
    "                        radius=radius,\n",
    "                      color= colour\n",
    "                       ).add_to(map_bcn)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "            [41.380711, 2.185559],\n",
    "            radius=15,\n",
    "            color='black',\n",
    "            fill=True,\n",
    "            fill_color='purple',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "\n",
    "map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's looking great.  Now lets start pulling our Foursquare data in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### 1.5.2 venue data <a name=\"\"></a>\n",
    "We'll need to set up our API credentials.\n",
    "I'm using the getenv library here to allow me to work with dynamic credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLIENT_ID =  os.getenv('FOURSQUARE_CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('FOURSQUARE_CLIENT_SECRET')\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentials:')\n",
    "#print('CLIENT_ID: '  + CLIENT_ID)\n",
    "#print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up our code to pull our venues in from the API. This code was originally based on the source code given in the course, but due to changes to the FourSquare  API reducing the numbers of venues available in each call from 100 to 50, I've modified it to allow it to pull in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LIMIT = 50\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radiuses):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng, radius in zip(names, latitudes, longitudes, radiuses):\n",
    "        #print('name:',name,' lat:',lat,' lng:',lng,' radius:',radius)\n",
    "        these_venues = getNearbyVenues2(name, lat,lng,radius)\n",
    "        venues_list = venues_list + these_venues\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venues_list])\n",
    "    nearby_venues.columns = ['neighbourhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category',\n",
    "                            'point']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getNearbyVenues2(name, latitude, longitude, radius):\n",
    "    this_list = []\n",
    "    print(name)\n",
    "    offset = 0\n",
    "    offset_max = 0\n",
    "    while(offset <= offset_max):\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&intent=checkin&llAcc=1&sortByPopularity=1&offset={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            latitude, \n",
    "            longitude, \n",
    "            radius, \n",
    "            LIMIT,\n",
    "            offset * LIMIT )\n",
    "        #print(url) \n",
    "        # make the GET request\n",
    "        raw = requests.get(url).json()\n",
    "        #print(raw)\n",
    "        results = requests.get(url).json()[\"response\"]\n",
    "        if(raw[\"response\"]):\n",
    "            totresults = raw[\"response\"][\"totalResults\"]\n",
    "            if(offset_max == 0 and totresults > 50):\n",
    "                offset_max = math.floor(totresults / 50)\n",
    "            results = raw[\"response\"]['groups'][0]['items']\n",
    "            #print(results)\n",
    "            # return only relevant information for each nearby venue\n",
    "            \n",
    "            for v in results:\n",
    "                #print(v)\n",
    "                this_list.append([\n",
    "                    name, \n",
    "                    latitude, \n",
    "                    longitude, \n",
    "                    v['venue']['name'], \n",
    "                    v['venue']['location']['lat'], \n",
    "                    v['venue']['location']['lng'],  \n",
    "                    v['venue']['categories'][0]['name'],\n",
    "                    Point(v['venue']['location']['lng'],v['venue']['location']['lat'])])\n",
    "            print('got batch ',offset+1 ,' for a total of ',len(results),' results')\n",
    "        offset += 1\n",
    "    return this_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets call for our smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_venues = getNearbyVenues(names=df_problems['neighbourhood'],\n",
    "                                   latitudes=df_problems['centre_lat'],\n",
    "                                   longitudes=df_problems['centre_lng'],\n",
    "                             radiuses=df_problems['radius']\n",
    "                                  )\n",
    "bcn_venues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine our venu data with the data from the neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bcn_merged = df_problems.merge(bcn_venues, how='inner',on='neighbourhood')\n",
    "bcn_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify if venues that were returned within the radius are actually within the neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within(row):\n",
    "    return row['point'].within(row['geometry'])\n",
    "\n",
    "bcn_merged['within'] = bcn_merged.apply(is_within, axis=1)\n",
    "#bcn_merged.head()\n",
    "bcn_one_district = bcn_merged[bcn_merged['LITERAL'].eq('032')]\n",
    "bcn_one_district = bcn_one_district.drop(['point'], axis=1)\n",
    "#bcn_one_district.head()\n",
    "#bcn_one_district.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets visualise it to see how accurate our calculations are for a single area.\n",
    "Green should be within the boundries, whereas red should be outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_function(feature):\n",
    "    if(feature['properties']['within'] == True):\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0,\n",
    "        'fillColor': color \n",
    "    }\n",
    "# create map of Barcelona using latitude and longitude values\n",
    "map_bcn = folium.Map(location=[df_problems.iloc[0].centre_lat, df_problems.iloc[0].centre_lng], zoom_start=15)\n",
    "if(venue_data_from_foursquare):\n",
    "\n",
    "    folium.GeoJson(\n",
    "        envelopes.to_json(),\n",
    "        name='geojson'\n",
    "    ).add_to(map_bcn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add markers to map\n",
    "    for lat, lng, borough, neighbourhood,colour,radius,within in zip(bcn_one_district['Venue Latitude'], bcn_one_district['Venue Longitude'], bcn_one_district['Nom_Barri'], bcn_one_district['Venue'],bcn_one_district['FHEX_COLOR'],bcn_one_district['radius'],bcn_one_district['within']):\n",
    "        label = '{}, {}'.format(neighbourhood, borough)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        if(within):\n",
    "            colour = 'green'\n",
    "        else:\n",
    "            colour = 'red'\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color=colour,\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "\n",
    "\n",
    "map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good, so new lets exclude the venues outside each area. and replot for our 3 districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barceloneta = bcn_merged[bcn_merged['within'].eq(True)]\n",
    "barceloneta = barceloneta.drop(['point'], axis=1)\n",
    "barceloneta.shape\n",
    "\n",
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillOpacity': 0.03,\n",
    "        'weight': 0,\n",
    "        'fillColor': feature['properties']['FHEX_COLOR'] \n",
    "    }\n",
    "if(venue_data_from_foursquare):\n",
    "    # create map of Barcelona using latitude and longitude values\n",
    "    map_bcn = folium.Map(location=[df_problems.iloc[0].centre_lat, df_problems.iloc[0].centre_lng], zoom_start=15)\n",
    "    folium.GeoJson(\n",
    "        barceloneta.to_json(),\n",
    "        name='geojson',\n",
    "        style_function=style_function\n",
    "    ).add_to(map_bcn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add markers to map\n",
    "    for lat, lng, borough, neighbourhood,colour,radius,within in zip(barceloneta['Venue Latitude'], barceloneta['Venue Longitude'], barceloneta['Nom_Barri'], bcn_one_district['Venue'],barceloneta['FHEX_COLOR'],barceloneta['radius'],barceloneta['within']):\n",
    "        label = '{}, {}'.format(neighbourhood, borough)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=5,\n",
    "            popup=label,\n",
    "            color=colour,\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=1,\n",
    "            parse_html=False).add_to(map_bcn)  \n",
    "\n",
    "\n",
    "map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, lets redo this for all of the districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_envelopes = df_hoods['geometry'].envelope\n",
    "df_hoods['radius'] = all_envelopes.apply(get_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot each centeroid and radius to see if it looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0,\n",
    "        'fillColor': feature['properties']['FHEX_COLOR'] \n",
    "    }\n",
    "\n",
    "# create map of Barcelona using latitude and longitude values\n",
    "map_bcn = folium.Map(location=[df_hoods.iloc[0].centre_lat, df_hoods.iloc[0].centre_lng], zoom_start=15)\n",
    "folium.GeoJson(\n",
    "    df_hoods.to_json(),\n",
    "    name='geojson',\n",
    "    style_function=style_function\n",
    ").add_to(map_bcn)\n",
    "\n",
    "\n",
    "folium.GeoJson(\n",
    "    envelopes.to_json(),\n",
    "    name='geojson'\n",
    ").add_to(map_bcn)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighbourhood,colour,radius in zip(df_hoods['centre_lat'], df_hoods['centre_lng'], df_hoods['Nom_Barri'], df_hoods['LITERAL'],df_hoods['FHEX_COLOR'],df_hoods['radius']):\n",
    "    label = '{}, {}'.format(neighbourhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=colour,\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_bcn)  \n",
    "    folium.Circle([lat, lng],\n",
    "                    radius=radius,\n",
    "                  color= colour\n",
    "                   ).add_to(map_bcn)\n",
    "\n",
    "folium.CircleMarker(\n",
    "        [41.380711, 2.185559],\n",
    "        radius=15,\n",
    "        color='black',\n",
    "        fill=True,\n",
    "        fill_color='purple',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_bcn)  \n",
    "\n",
    "#map_bcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - Looks right.\n",
    "So becuase we're going to make a large number of API calls, we should set things up so we get interrupted in process, we can start off where we'd got to.\n",
    "To do this, we'll use a received_venues column, which will allow us to identify neighbourhoods that we've already processed.\n",
    "We'll also set up a dataframe for all the venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods['received_venues'] = False\n",
    "df_hoods['received_venues_cnt'] = 0\n",
    "venue_columns = ['neighbourhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category',\n",
    "                            'point']\n",
    "df_hoods_venues = pd.DataFrame(columns = venue_columns)\n",
    "#df_hoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've already pulled our data and saved it, let's reload it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(load_venues_from_file):\n",
    "    print(\"Loading already pulled data from file\")\n",
    "    loaded_venues = pickle.load( open( \"venuesAll.pkl\", \"rb\" ) )\n",
    "    loaded_hoods = pickle.load( open( \"df_hoods.pkl\", \"rb\" ) )\n",
    "    df_hoods_venues = loaded_venues\n",
    "    df_hoods = loaded_hoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run for all our neighbourhoods in Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(load_venue_data_from_api == False):\n",
    "    print(\"Skipping loading from the foursquare api\")\n",
    "else:\n",
    "    for ind in df_hoods.index: \n",
    "            this_hood = df_hoods.iloc[ind]\n",
    "            if (this_hood['received_venues']):\n",
    "                 print(this_hood['neighbourhood'], ' : already processed') \n",
    "            elif ind > 5000:\n",
    "                #print(this_hood['neighbourhood'], ' : skipping') \n",
    "                x = 1\n",
    "            else:\n",
    "                #print(this_hood['neighbourhood'], ' : requesting') \n",
    "                these_venues = getNearbyVenues2(name=this_hood['neighbourhood'] , latitude=this_hood['centre_lat'],longitude=this_hood['centre_lng'],radius=this_hood['radius'])\n",
    "                print(these_venues)\n",
    "\n",
    "                if(len(these_venues)> 0  and len(these_venues[0]) > 0):\n",
    "                    these_venues_df = pd.DataFrame([item for these_venues in these_venues for item in these_venues])\n",
    "\n",
    "                    these_venues_df.columns = ['neighbourhood', \n",
    "                          'Neighborhood Latitude', \n",
    "                          'Neighborhood Longitude', \n",
    "                          'Venue', \n",
    "                          'Venue Latitude', \n",
    "                          'Venue Longitude', \n",
    "                          'Venue Category',\n",
    "                                    'point']\n",
    "\n",
    "                    df_hoods_venues = df_hoods_venues.append(these_venues_df)\n",
    "                    df_hoods['received_venues'][ind] = True\n",
    "                    df_hoods['received_venues_cnt'][ind] = len(these_venues_df)\n",
    "                    print(this_hood['neighbourhood'], ' : got ',len(these_venues_df), ' venues') \n",
    "                else:\n",
    "                    print(this_hood['neighbourhood'], ' : got 0 venues') \n",
    "                    df_hoods['received_venues'][ind] = False\n",
    "                    df_hoods['received_venues_cnt'][ind] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As loading out the venue data took a bunch of time, lets save it to disk so we don't need to redo it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this out to actually (over)write the saved venue data\n",
    "if(write_venues_to_file):\n",
    "    print(\"Writing venue data to file\")\n",
    "    pickle.dump( df_hoods_venues, open( \"venuesAllNew.pkl\", \"wb\" ) )\n",
    "    pickle.dump( df_hoods, open( \"df_hoods.pkl\", \"wb\" ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 1.6 venue category taxonomy from FourSquare <a id=\"data6\"></a>\n",
    "In order to be able to roll up different venue types - all restaurants rather than Chineese, Tapas etc, we'll need to get the FourSquare venue categogry taxonomy from the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcategories():\n",
    "    this_list = []\n",
    "    # create the API request URL\n",
    "    url = 'https://api.foursquare.com/v2/venues/categories?&client_id={}&client_secret={}&v={}'.format(\n",
    "        CLIENT_ID, \n",
    "        CLIENT_SECRET, \n",
    "        VERSION )\n",
    "    #print(url) \n",
    "    # make the GET request\n",
    "    raw = requests.get(url).json()\n",
    "    #print(raw)\n",
    "    #results = requests.get(url).json()[\"response\"]\n",
    "    if(raw[\"response\"]):\n",
    "        results = raw[\"response\"]['categories']\n",
    "        #print(type(results))\n",
    "        for r in results:\n",
    "            this_master_category = r['name']\n",
    "            print(this_master_category)\n",
    "            this_list = recursive_categories(this_master_category, this_list, r)\n",
    "    return this_list\n",
    "\n",
    "def recursive_categories(main_name, arr, obj):\n",
    "    #print(type(obj))\n",
    "    for r in obj['categories']:\n",
    "        this_name = r['name']\n",
    "        #print(this_name)\n",
    "        arr.append([this_name ,main_name])\n",
    "        #print(r['categories'])\n",
    "        if(len(r['categories']) > 0):\n",
    "            arr = recursive_categories(main_name, arr, r)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame(getcategories(), columns =['subcategory', 'category']).set_index('subcategory')\n",
    "cat_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br><br><br>\n",
    "## 2. data processing <a id=\"processing\"></a>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge our neighbourhood data with the venue data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_merged_all = df_hoods.merge(loaded_venues, how='inner',on='neighbourhood')\n",
    "bcn_merged_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the venues which are actually within our neighbourhood (vs just being in the radius) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_merged_all['within'] = bcn_merged_all.apply(is_within, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new dataset for only the venues actually with the district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_within = bcn_merged_all[bcn_merged_all['within'].eq(True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add our FourSquare category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_within_with_cats = only_within.join(cat_df,on='Venue Category')\n",
    "only_within_with_cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets one hot encode our data, both by the venue type and the venue category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "bcn_all_onehot = pd.get_dummies(only_within[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "bcn_all_onehot_cats = pd.get_dummies(only_within_with_cats[['category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "bcn_all_onehot['Nom_Districte'] = only_within['Nom_Districte'] \n",
    "bcn_all_onehot['Nom_Barri'] = only_within['Nom_Barri'] \n",
    "bcn_all_onehot['neighbourhood'] = only_within['neighbourhood'] \n",
    "bcn_all_onehot['price_per_m2'] = only_within['price_per_m2'] \n",
    "bcn_all_onehot_cats['Nom_Districte'] = only_within_with_cats['Nom_Districte'] \n",
    "bcn_all_onehot_cats['Nom_Barri'] = only_within_with_cats['Nom_Barri'] \n",
    "bcn_all_onehot_cats['neighbourhood'] = only_within_with_cats['neighbourhood'] \n",
    "bcn_all_onehot_cats['price_per_m2'] = only_within_with_cats['price_per_m2'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = list(bcn_all_onehot.columns[-3:]) + list(bcn_all_onehot.columns[:-3])\n",
    "fixed_columns_cats = list(bcn_all_onehot_cats.columns[-3:]) + list(bcn_all_onehot_cats.columns[:-3])\n",
    "#fixed_columns = [bcn_onehot.columns[-1]] + list(bcn_onehot.columns[:-1])\n",
    "bcn_all_onehot = bcn_all_onehot[fixed_columns]\n",
    "bcn_all_onehot_cats = bcn_all_onehot_cats[fixed_columns_cats]\n",
    "#fixed_columns\n",
    "bcn_all_onehot_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped_cats = bcn_all_onehot_cats.groupby(['Nom_Barri','price_per_m2']).mean().reset_index()\n",
    "bcn_grouped_cats.head()\n",
    "bcn_grouped_hoods = bcn_all_onehot.groupby(['neighbourhood','price_per_m2']).mean().reset_index()\n",
    "bcn_grouped_hoods_cats = bcn_all_onehot_cats.groupby(['neighbourhood','price_per_m2']).mean().reset_index()\n",
    "bcn_grouped_hoods_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_sum = bcn_all_onehot.groupby(['Nom_Barri','price_per_m2']).sum().reset_index()\n",
    "bcn_sum_cats = bcn_all_onehot_cats.groupby(['Nom_Barri','price_per_m2']).sum().reset_index()\n",
    "bcn_sum_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped = bcn_all_onehot.groupby(['Nom_Barri','price_per_m2']).mean().reset_index()\n",
    "bcn_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br><br><br>\n",
    "## 3. investigations <a id=\"investigations\"></a>\n",
    "---\n",
    "Here we can start to use our data to make our investigations, specificaly we're going to:\n",
    "1. Which areas are more or less expensive?\n",
    "2. How can we group areas based on the type of venues they contain?\n",
    "3. What type of venues correlate with richer or poorer areas?\n",
    "4. Which areas appear over or under valued based on their venues?\n",
    "\n",
    "\n",
    "<br><br>\n",
    "### 3.1 price by district <a id=\"inv1\"></a>\n",
    "Let's check that our data makes sense by trying to map it using a clorapleth map.\n",
    "First we'll extract just our prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = df_hoods[['id','price_per_m2']]\n",
    "prices['id'] = prices['id'].astype('str')\n",
    "prices.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will check that geolocation isworking correctly to centre our maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to draw our clorapeth map where the cheapest areas being shown in yellow, and the most expensive shown in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "if(price_by_district):\n",
    "    bins = list(prices['price_per_m2'].quantile([0, 0.25, 0.5, 0.75, 1]))\n",
    "\n",
    "   \n",
    "\n",
    "    # Add the color for the chloropleth:\n",
    "    folium.Choropleth(\n",
    "     geo_data=df_hoods.to_json(),\n",
    "     name='choropleth',\n",
    "     data=prices,\n",
    "     columns=['id','price_per_m2'],\n",
    "     key_on='feature.id',\n",
    "     fill_color='YlGn',\n",
    "     fill_opacity=0.7,\n",
    "     line_opacity=0.8,\n",
    "     #bins=bins,\n",
    "     legend_name='price per sq m',\n",
    "     reset=True\n",
    "    ).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 3.2 price effect each type of venue <a id=\"inv2\"></a>\n",
    "So let's see what venues are associated with higher price areas and which with lower price areas.\n",
    "We'll take our one hot encoded data, create the avg by sub-neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to apply Linear Regression in order to identify the correlation between venue proportion and price. To start we're going to split off our categories as our idenpendant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_colnames = bcn_grouped.columns[2:]\n",
    "x_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we use price per m2 as the dependent variable and run our regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "x = np.asanyarray(bcn_grouped[x_colnames])\n",
    "y = np.asanyarray(bcn_grouped['price_per_m2'])\n",
    "regr.fit (x, y)\n",
    "# The coefficients\n",
    "print ('Coefficients: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our coefficients show how strongly correlated a certain venue type is with a higher or lower price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'category':x_colnames, 'importance':regr.coef_ }\n",
    "category_df = pd.DataFrame(dict)\n",
    "category_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots sort and scale them so we can better identify the reletive strength of the correlations.\n",
    "From here we have a comprehensive list of all the different types of venues that exist in Barcelona, and how correlated they are with property price.\n",
    "We can see that having a Pub in an area is most correlated with a lower price, and having a Beach bar most correlated with a higher price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.sort_values(by=['importance'], inplace=True)\n",
    "max_val = max(category_df['importance'].max(),abs(category_df['importance'].min()))\n",
    "category_df['scaled'] = (category_df['importance'] / max_val) * 100\n",
    "category_df.set_index(['category'],inplace=True)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.to_excel('coeficients.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 3.3 identifying types of district <a id=\"inv3\"></a>\n",
    "By looking at the types and frequency of venue types in each district, are we able to identify neighbourhoods which are similar to each other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[2:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Nom_Barri']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighbourhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighbourhoods_venues_sorted['Nom_Barri'] = bcn_grouped['Nom_Barri']\n",
    "\n",
    "for ind in np.arange(bcn_grouped.shape[0]):\n",
    "    neighbourhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(bcn_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighbourhoods_venues_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 9\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Nom_Barri']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighbourhoods_venues_sorted_cat = pd.DataFrame(columns=columns)\n",
    "neighbourhoods_venues_sorted_cat['Nom_Barri'] = bcn_grouped_cats['Nom_Barri']\n",
    "\n",
    "for ind in np.arange(bcn_grouped_cats.shape[0]):\n",
    "    neighbourhoods_venues_sorted_cat.iloc[ind, 1:] = return_most_common_venues(bcn_grouped_cats.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighbourhoods_venues_sorted_cat.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 8\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['neighbourhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "sub_neighbourhoods_venues_sorted_cat = pd.DataFrame(columns=columns)\n",
    "sub_neighbourhoods_venues_sorted_cat['neighbourhood'] = bcn_grouped_hoods_cats['neighbourhood']\n",
    "\n",
    "for ind in np.arange(bcn_grouped_hoods_cats.shape[0]):\n",
    "    sub_neighbourhoods_venues_sorted_cat.iloc[ind, 1:] = return_most_common_venues(bcn_grouped_hoods_cats.iloc[ind, :], num_top_venues)\n",
    "\n",
    "sub_neighbourhoods_venues_sorted_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcn_grouped = bcn_onehot.groupby('neighbourhood').mean().reset_index()\n",
    "bcn_grouped_hoods_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcn_grouped_clustering = bcn_grouped.drop(['Nom_Barri','price_per_m2'], 1)\n",
    "#bcn_grouped_clustering = bcn_grouped_cats.drop(['Nom_Barri','price_per_m2'], 1)\n",
    "bcn_grouped_clustering = bcn_grouped_hoods_cats.drop(['neighbourhood','price_per_m2'], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(bcn_grouped_clustering)\n",
    "    kmeanModel.fit(bcn_grouped_clustering)\n",
    "    distortions.append(sum(np.min(cdist(bcn_grouped_clustering, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / bcn_grouped_clustering.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(bcn_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "#bcn_grouped.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "\n",
    "#bcn_grouped['Cluster Labels'] =  kmeans.labels_\n",
    "#bcn_grouped_cats['Cluster Labels'] =  kmeans.labels_\n",
    "bcn_grouped_hoods_cats['Cluster Labels'] =  kmeans.labels_\n",
    "#tor_merged = neighbourhoods\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "#tor_merged = tor_merged.join(neighbourhoods_venues_sorted.set_index('Neighbourhood'), how='inner', on='Neighbourhood')\n",
    "\n",
    "#bcn_grouped_cats.head() # check the last columns!\n",
    "bcn_grouped_hoods_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_neighbourhoods_venues_sorted_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods_k_means = df_hoods.merge(bcn_grouped_hoods_cats.set_index('neighbourhood'), how='inner', on='neighbourhood')\n",
    "df_hoods_k_means = df_hoods_k_means.merge(sub_neighbourhoods_venues_sorted_cat.set_index('neighbourhood'), how='inner', on='neighbourhood')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df_hoods_k_means, values=['Arts & Entertainment','College & University','Food','Nightlife Spot','Outdoors & Recreation','Professional & Other Places','Residence','Shop & Service','Travel & Transport'], index=['Cluster Labels'], aggfunc=np.mean)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our clusters could be described as:\n",
    "\n",
    "| Cluster | Description   |\n",
    "|------|------|\n",
    "|   0  | food/shops|\n",
    "|   1  | food|\n",
    "|   2  | recreation|\n",
    "|   3  | nightlife|\n",
    "|   3  | arts/food/recreation|\n",
    "|   5  | shops|\n",
    "|   6  | travel/transport|\n",
    "|   7  | food/recreation/nightlife|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_data = {'Cluster Labels': [0,1,2,3,4,5,6,7],\n",
    "        'Description': ['food/shops','mostly food','mostly recreation','nightlife','arts/food/recreation','mostly shopping','travel/transport','food/recreation/nightlife']\n",
    "        }\n",
    "\n",
    "df_desc = pd.DataFrame(desc_data, columns = ['Cluster Labels', 'Description'])\n",
    "df_desc.set_index('Cluster Labels',inplace=True)\n",
    "\n",
    "print (df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods_k_means = df_hoods_k_means.merge(df_desc, how='inner', on='Cluster Labels')\n",
    "cat_lookups = df_hoods_k_means[['neighbourhood','Description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_lookups.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hoods_k_means_dist = df_hoods.merge(bcn_grouped_cats.set_index('Nom_Barri'), how='inner', on='Nom_Barri')\n",
    "\n",
    "\n",
    "\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    " \n",
    "# Add the color for the chloropleth:\n",
    "choropleth = folium.Choropleth(\n",
    " geo_data=df_hoods_k_means.to_json(),\n",
    " name='choropleth',\n",
    " data=df_hoods_k_means,\n",
    " columns=['SEC_CENS','Cluster Labels'],\n",
    " key_on='feature.properties.SEC_CENS',\n",
    " fill_color='Set1',\n",
    " fill_opacity=0.7,\n",
    " line_opacity=0.2,\n",
    " legend_name='Cluster',\n",
    " reset=True\n",
    ").add_to(m)\n",
    "\n",
    "\n",
    "# add labels indicating the name of the community\n",
    "style_function = \"font-size: 15px; font-weight: bold\"\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['Description'], style=style_function, labels=False))\n",
    "\n",
    "# create a layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_segment_map(dt):\n",
    "\n",
    "    #seg_data = dt[['id','price_per_m2_x']]\n",
    "    #dt['id'] = dt['id'].astype('str')\n",
    "    geo = dt[['SEC_CENS','geometry','neighbourhood','price_per_m2_x']] \n",
    "\n",
    "    m = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "    # Add the color for the chloropleth:\n",
    "    choropleth = folium.Choropleth(\n",
    "     geo_data=geo.to_json(),\n",
    "     name='choropleth',\n",
    "     data=geo,\n",
    "     columns=['SEC_CENS','price_per_m2_x'],\n",
    "     key_on='feature.properties.SEC_CENS',\n",
    "     fill_color='RdYlGn', \n",
    "     fill_opacity=0.7,\n",
    "     line_opacity=1,\n",
    "     legend_name='relative price',\n",
    "     highlight=True,smooth_factor=0\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "    # add labels indicating the name of the community\n",
    "    style_function = \"font-size: 15px; font-weight: bold\"\n",
    "    choropleth.geojson.add_child(\n",
    "        folium.features.GeoJsonTooltip(['price_per_m2_x'], style=style_function, labels=False))\n",
    "\n",
    "    # create a layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "    stats = geo.sort_values(by=['price_per_m2_x']);\n",
    "    stats = stats[['neighbourhood','price_per_m2_x']]\n",
    "    stats.set_index('neighbourhood')\n",
    "    print('Looking at Neighbourhoods of Type: ' + dt.Description.values[0] )\n",
    "    print('Top 5 Lowest Priced Neighbourhoods')\n",
    "    print(stats.head(5))\n",
    "    stats.sort_values(by=['price_per_m2_x'],ascending=False,inplace= True);\n",
    "    print('Top 5 Highest Priced Neighbourhoods')\n",
    "    print(stats.head(5))\n",
    "\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(0)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(1)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(2)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(3)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(4)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(5)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(6)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = df_hoods_k_means[df_hoods_k_means['Cluster Labels'].eq(7)] \n",
    "m = build_segment_map(cat1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 3.4 underpriced/overpriced neighbourhoods by venue <a id=\"inv4\"></a>\n",
    "By looking at the types and frequency of venue types in each district, are we able to identify neighbourhoods which are similar to each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#top\">back to top</a> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat= regr.predict(bcn_grouped[x_colnames])\n",
    "bcn_grouped['predicted_price'] = y_hat\n",
    "bcn_grouped = bcn_grouped.astype({\"predicted_price\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped['price_delta'] = bcn_grouped['price_per_m2'] - bcn_grouped['predicted_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcn_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped_neigh = bcn_all_onehot.groupby(['neighbourhood','price_per_m2']).mean().reset_index()\n",
    "#bcn_grouped_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_hat= regr.predict(bcn_grouped_neigh[x_colnames])\n",
    "bcn_grouped_neigh['predicted_price'] = y_hat\n",
    "bcn_grouped_neigh = bcn_grouped_neigh.astype({\"predicted_price\": int})\n",
    "bcn_grouped_neigh['price_delta'] = bcn_grouped_neigh['price_per_m2'] - bcn_grouped_neigh['predicted_price']\n",
    "bcn_grouped_neigh['price_diff'] = (bcn_grouped_neigh['price_delta']/bcn_grouped_neigh['price_per_m2']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn_grouped_neigh.head(50)\n",
    "df_hoods_price_diff = df_hoods_k_means.merge(bcn_grouped_neigh.set_index('neighbourhood'), how='inner', on='neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hoods_price_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prices_diff = df_hoods_price_diff[['SEC_CENS','price_diff']]\n",
    "bins = list(prices_diff['price_diff'].quantile([0, 0.25, 0.5, 0.75, 1]))\n",
    "bins = list(prices_diff['price_diff'].quantile([0, 0.1, 0.2, 0.3, 0.4,0.5,0.6,0.7,0.8,0.9,1]))\n",
    "prices_diff['price_diff_quart'] = prices_diff['price_diff'].quantile([0, 0.1, 0.2, 0.3, 0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    " \n",
    "# Add the color for the chloropleth:\n",
    "choropleth = folium.Choropleth(\n",
    " geo_data=df_hoods_price_diff.to_json(),\n",
    " name='choropleth',\n",
    " data=prices_diff,\n",
    " columns=['SEC_CENS','price_diff'],\n",
    " key_on='feature.properties.SEC_CENS',\n",
    " fill_color='RdYlGn',\n",
    " fill_opacity=0.7,\n",
    " line_opacity=0.2,\n",
    " bins=bins,\n",
    " legend_name='difference from predicted price',\n",
    " reset=True\n",
    ").add_to(m)\n",
    "\n",
    "style_function = \"font-size: 15px; font-weight: bold\"\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['Description'], style=style_function, labels=False))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
